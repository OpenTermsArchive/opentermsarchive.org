---
html_description: 
title: X focuses its automated enforcement on child protection in the UK
service: X
terms_types: ["Community Guidelines"]
dates: ["2026-01-27"]
author: ["tam kien duong"]
related_collections: ["vlopses-gb"]
---

X [added](https://github.com/OpenTermsArchive/vlopses-gb-versions/commit/d619be0c9a920f4f9a3d0685a1d9ed1cb4073cfa) clarifications regarding the automated enforcement of child protection regulations. This change has only been detected in the UK jurisdiction, and its language and references are specific to this area.

The introduction to the methodology of ‘automated content enforcement’ mentioned the use of ‘artificial intelligence models’ alongside ‘heuristics, and machine learning algorithms’. This change does not significantly impact the system and mainly updates the latest language.

A short explanation of how the supervised machine learning model operates has been replaced by a longer explanation in dedicated paragraphs. The example mostly focuses on how automated decisions are used to protect children. It insists on using both internal tools and third-party services. Additionally, it notes that ‘proprietary technology is steadily reducing the burden on people to report this content’.

Two sections have been added on reporting non-compliance with the [UK's Online Safety Act](https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer) and on issues concerning ‘proactive technology’. Mostly, it provides links to relevant forms to file reports.

Seven occurrences of the term ‘content harmful to children’ have been added throughout the document.

The majority of these modifications focus on protecting children from exposure to sensitive content and children’s protection. This must be balanced with the creation of synthetic content that depicts children.

[X](https://en.wikipedia.org/wiki/Twitter), formerly known as Twitter, is a social media platform owned by Elon Musk. [Grok](https://en.wikipedia.org/wiki/Grok_\(chatbot\)) is a generative artificial intelligence service run by [xAI](https://en.wikipedia.org/wiki/XAI_\(company\)), X’s parent company, that is fully integrated into X. In July 2025, a new version of its image and video generation tool was released, including a ‘spicy’ mode that removes protections regarding adult content. Since December 2025, media and regulators have [reported](https://apnews.com/article/grok-x-musk-ai-nudification-abuse-2021bbdb508d080d46e3ae7b8f297d36) on the persistent use of these tools to produce sexually suggestive images of young women or girls, which are then shared through X.

On January 12, 2026, [the UK regulator for communication services, Ofcom](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/ofcom-launches-investigation-into-x-over-grok-sexualised-imagery), launched an investigation into this service. [Other regulators](https://www.techpolicy.press/regulators-are-going-after-grok-and-x-just-not-together/), including [the EU Commission](https://www.theguardian.com/technology/2026/jan/26/eu-launches-inquiry-into-x-over-sexually-explicit-images-made-by-grok-ai), are also investigating the same issue.
