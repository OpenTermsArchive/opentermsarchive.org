---
html_description: Facebook now removes accounts for interacting with violating content, using behavioral signals that may cause overreaching enforcement.
title: Facebook can now remove accounts for interacting with violating content
service: Facebook
terms_types: ["Community Guidelines"]
dates: ["2025-09-20"]
author: Saumyaa Naidu
related_collections: ["pga"]
---

Facebook [updated](https://github.com/OpenTermsArchive/pga-versions/commit/8db591d1ecca55b871b200a6ac039e27cfc5eee2#diff-02024f8771e7c160c1ea6dedb238431cf8900d7c24b2ac0a13dd85c42ac3be96R1253) the human exploitation provision in their Community Guidelines to remove accounts based on their interactions with violating accounts, content, and groups. Based on the policy, violating accounts are those posting content that “recruits people for, facilitates, or exploits people through human trafficking”. Facebook will categorise interactions with such accounts as “behavioral signals” to detect and take action on violating accounts. This section of the policy no longer specifies removing content that offers jobs in areas flagged as high-risk for labor exploitation by law enforcement and local NGOs. However, it is still mentioned under the standards that require additional information and/or context to enforce. 

Based on the change, Facebook sees interactions with violating accounts on the platform as signals for harmful activity, and may not require additional information to take action. This can cause overreaching enforcement and lead to unwarranted removal of accounts based on association as opposed to any direct violation. 
