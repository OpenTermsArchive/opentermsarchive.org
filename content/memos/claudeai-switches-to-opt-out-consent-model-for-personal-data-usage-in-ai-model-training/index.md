---
html_description: Claude.ai is updating its Privacy Policy on September 25, 2025, shifting from opt-in to opt-out data use for model training.
title: Claude.ai switches to opt-out consent model for personal data usage in AI model training
service: Claude.ai
terms_types: ["Privacy Policy"]
dates: ["2025-08-29"]
author: Sydney Wheeler
related_collections: ["genai"]
assistance: [GPT-4o]
---

Claude.ai [revised](https://github.com/OpenTermsArchive/GenAI-versions/commit/e59bf71c68398878e7d12ccdf99d89af5f0984ed#diff-51c25e106bedcf49c2924f4875242cdb6ca536bd26d2415726c5f59131aa0be4R73) its Privacy Policy, **moving from an opt-in to an opt-out consent model**. The updated terms, which go into effect on September 25, 2025, state that Input and Output data may be used to train models and improve services **unless users disable this setting in their account**. Previously, such data was only used for training if users explicitly enabled the setting. The update also adds device location to the categories of personal data automatically collected when using the service.

Under the new terms, even if users opt out, Anthropic, Claude.ai’s parent company, may still process content that is flagged for safety review or explicitly reported via feedback mechanisms. The update also clarifies the categories of personal data collected from third-party sources and replaces references to the former Model Training Notice with a link to a newly separated [Non-User Privacy Policy](https://www.anthropic.com/legal/non-user-privacy-policy).

The revision was accompanied by an [email](2025-09-02-claude-ai-update-notification-screenshot.png) to users announcing the update and highlighting the main changes. It further states that data may be used in the “legitimate interest” of ensuring that “artificial intelligence has a positive impact on society as it becomes increasingly advanced and capable,” aligning with Anthropic’s brand image as an “AI safety and research company.”

This shift places Anthropic and Claude.ai alongside other major AI providers using opt-out data collection models for training, a practice that has raised concerns about user agency, as publications such as [Wired](https://www.wired.com/story/how-to-stop-your-data-from-being-used-to-train-ai/), the [New York Times](https://www.nytimes.com/article/meta-ai-scraping-policy.html), and the [Washington Post](https://www.washingtonpost.com/technology/2024/09/23/linkedin-training-ai-setting-opt-out/) have reported on since 2024.
