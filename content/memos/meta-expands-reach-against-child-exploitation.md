---
html_description: "Meta has extended the rules on child exploitation on Facebook and Instagram to include any activity related to such acts, raising questions about the moderation of private discussions and the management of sensitive content despite reporting obligations."
title: "Meta expands reach against child exploitation"
service: "Facebook"
terms_types: ["Community Guidelines – Child Exploitation"]
dates: ["2022-06-13"]
---

The section on child exploitation for both Facebook and Instagram [expanded](https://github.com/OpenTermsArchive/france-elections-versions/commit/0396436542fa7ef8dd8ae4dd02ff0ed5500e08a2) to cover not only publications that exploit minors, but also “any activity” related to such acts.

This opens up the question of moderation of private discussions, as social platforms show difficulties in managing content related to child abuse —as recently as late March, the New York Times [showed](https://www.nytimes.com/2022/03/31/business/meta-child-sexual-abuse.html) that moderation remains very light in this area, even though platforms are supposed to list this type of content and [report it](https://www.theverge.com/2022/3/31/23005576/facebook-content-moderators-child-sexual-abuse-material-csam-policy) to authorities.
